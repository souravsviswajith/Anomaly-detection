{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 1: Imports and Setup ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "# Ignore specific warnings that might clutter the output (optional)\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "\n",
        "print(\"--- Setup ---\")\n",
        "# Define the path to your already uploaded CSV file\n",
        "invoices_file_path = '/content/invoices.csv'\n",
        "model_save_path = \"/content/\" # Save directly in /content/\n",
        "model_filename = \"anomaly_model.pkl\"\n",
        "encoder_filename = \"encoders.pkl\"\n",
        "model_filepath = os.path.join(model_save_path, model_filename)\n",
        "encoder_filepath = os.path.join(model_save_path, encoder_filename)\n",
        "\n",
        "\n",
        "# Check if the invoice file exists\n",
        "if not os.path.exists(invoices_file_path):\n",
        "    raise FileNotFoundError(f\"Error: The file '{invoices_file_path}' was not found in the Colab environment. Please make sure it's uploaded to /content/\")\n",
        "else:\n",
        "    print(f\"Using invoice data file: {invoices_file_path}\")\n",
        "    print(f\"Model will be saved to/loaded from: {model_save_path}\")\n",
        "\n",
        "# --- Cell 2: Data Loading and Preprocessing Definition ---\n",
        "print(\"\\n--- Defining Preprocessing Function ---\")\n",
        "# (preprocess_data function remains the same as the corrected previous version)\n",
        "def preprocess_data(csv_file_path):\n",
        "    \"\"\"Loads, preprocesses, and returns the invoice data, label encoders, and columns used.\"\"\"\n",
        "    print(f\"Reading CSV from: {csv_file_path}\")\n",
        "    try:\n",
        "        # Read CSV, try to infer initial types but be ready to correct\n",
        "        df = pd.read_csv(csv_file_path, low_memory=False)\n",
        "        print(f\"Initial DataFrame shape: {df.shape}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: CSV file not found at {csv_file_path}\")\n",
        "        return None, None, None\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading CSV: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "    le_dict = {}  # Store label encoders\n",
        "    categorical_cols = ['first_name', 'last_name', 'email', 'address', 'city', 'stock_code', 'job']\n",
        "    numeric_cols_base = ['qty', 'amount', 'product_id'] # Base numeric columns\n",
        "\n",
        "    # Create a copy for processing\n",
        "    df_processed = df.copy()\n",
        "\n",
        "    # 1. Handle Categorical Columns\n",
        "    print(\"Encoding categorical columns...\")\n",
        "    for col in categorical_cols:\n",
        "        if col in df_processed.columns: # Check if column exists\n",
        "            le = LabelEncoder()\n",
        "            # Convert to string robustly, handling potential NaN/mixed types\n",
        "            df_processed[col] = df_processed[col].fillna('missing').astype(str)\n",
        "            df_processed[col] = le.fit_transform(df_processed[col])\n",
        "            le_dict[col] = le\n",
        "        else:\n",
        "            print(f\"Warning: Categorical column '{col}' not found. Skipping.\")\n",
        "\n",
        "    # 2. Handle Date Column\n",
        "    print(\"Processing invoice date...\")\n",
        "    if 'invoice_date' in df_processed.columns:\n",
        "        df_processed['invoice_date'] = pd.to_datetime(df_processed['invoice_date'], format='%d/%m/%Y', errors='coerce')\n",
        "        original_rows = len(df_processed)\n",
        "        df_processed.dropna(subset=['invoice_date'], inplace=True)\n",
        "        rows_dropped = original_rows - len(df_processed)\n",
        "        if rows_dropped > 0:\n",
        "            print(f\"Warning: Dropped {rows_dropped} rows due to invalid date formats in 'invoice_date'.\")\n",
        "\n",
        "        if not df_processed.empty:\n",
        "            df_processed['invoice_day'] = df_processed['invoice_date'].dt.day\n",
        "            df_processed['invoice_month'] = df_processed['invoice_date'].dt.month\n",
        "            df_processed['invoice_year'] = df_processed['invoice_date'].dt.year\n",
        "            df_processed.drop('invoice_date', axis=1, inplace=True)\n",
        "            date_cols_created = ['invoice_day', 'invoice_month', 'invoice_year']\n",
        "        else:\n",
        "             print(\"Warning: DataFrame became empty after handling invalid dates. No data to process.\")\n",
        "             return None, le_dict, None\n",
        "    else:\n",
        "        print(\"Warning: 'invoice_date' column not found. Date features not created.\")\n",
        "        date_cols_created = []\n",
        "\n",
        "    # 3. Identify Final Columns for Model Training\n",
        "    final_model_cols = [col for col in numeric_cols_base if col in df_processed.columns]\n",
        "    final_model_cols.extend(le_dict.keys())\n",
        "    final_model_cols.extend(date_cols_created)\n",
        "    final_model_cols = sorted(list(dict.fromkeys(final_model_cols)))\n",
        "    final_model_cols = [col for col in final_model_cols if col in df_processed.columns]\n",
        "\n",
        "    if not final_model_cols:\n",
        "        print(\"Error: No valid columns identified for model training after preprocessing.\")\n",
        "        return None, le_dict, None\n",
        "\n",
        "    print(f\"Columns selected for model training: {final_model_cols}\")\n",
        "    df_final = df_processed[final_model_cols].copy()\n",
        "\n",
        "    # 4. Final Conversion to Numeric and Handling NaNs\n",
        "    for col in df_final.columns:\n",
        "         df_final[col] = pd.to_numeric(df_final[col], errors='coerce')\n",
        "\n",
        "    initial_nan_count = df_final.isnull().sum().sum()\n",
        "    if initial_nan_count > 0:\n",
        "        print(f\"Warning: Found {initial_nan_count} NaN values after processing. Filling with 0.\")\n",
        "        df_final.fillna(0, inplace=True)\n",
        "\n",
        "    print(\"Final DataFrame info before returning:\")\n",
        "    df_final.info(verbose=False) # Less verbose output\n",
        "\n",
        "    return df_final, le_dict, df_final.columns\n",
        "\n",
        "\n",
        "# --- Cell 3: Model Training and Saving Definition ---\n",
        "print(\"\\n--- Defining Model Training Function ---\")\n",
        "# (train_and_save_model function remains the same as the corrected previous version)\n",
        "def train_and_save_model(df, le_dict, model_filename=\"anomaly_model.pkl\", encoder_filename=\"encoders.pkl\", save_path=\"/content/\"):\n",
        "    \"\"\"Trains the Isolation Forest model and saves it along with the encoders.\"\"\"\n",
        "    if df is None or df.empty:\n",
        "        print(\"Error: DataFrame is empty or None. Cannot train model.\")\n",
        "        return None, None\n",
        "\n",
        "    non_numeric_cols = df.select_dtypes(exclude=[np.number]).columns\n",
        "    if not non_numeric_cols.empty:\n",
        "        print(f\"ERROR: Non-numeric columns detected before fitting: {non_numeric_cols.tolist()}. Check preprocessing.\")\n",
        "        for col in non_numeric_cols:\n",
        "             df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "        df.fillna(0, inplace=True)\n",
        "        non_numeric_cols = df.select_dtypes(exclude=[np.number]).columns\n",
        "        if not non_numeric_cols.empty:\n",
        "            print(\"ERROR: Could not convert all columns to numeric. Aborting training.\")\n",
        "            return None, None\n",
        "        else:\n",
        "             print(\"Warning: Had to perform extra numeric conversion before fitting.\")\n",
        "\n",
        "\n",
        "    if df.isnull().values.any():\n",
        "        print(\"Warning: NaN values detected before fitting. Filling with 0.\")\n",
        "        df.fillna(0, inplace=True)\n",
        "\n",
        "    model = IsolationForest(contamination=0.01, random_state=42)\n",
        "    print(f\"Fitting Isolation Forest model on {df.shape[0]} samples and {df.shape[1]} features...\")\n",
        "\n",
        "    try:\n",
        "        model.fit(df)\n",
        "        print(\"Model fitting complete.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error fitting the model: {e}\")\n",
        "        print(\"Columns:\", df.columns)\n",
        "        print(\"Data types:\\n\", df.dtypes)\n",
        "        print(\"Sample data:\\n\", df.head())\n",
        "        return None, None\n",
        "\n",
        "    model_filepath = os.path.join(save_path, model_filename)\n",
        "    encoder_filepath = os.path.join(save_path, encoder_filename)\n",
        "\n",
        "    try:\n",
        "        with open(model_filepath, 'wb') as f:\n",
        "            pickle.dump(model, f)\n",
        "        with open(encoder_filepath, 'wb') as f:\n",
        "            pickle.dump(le_dict, f)\n",
        "        print(f\"Model successfully saved to: {model_filepath}\")\n",
        "        print(f\"Encoders successfully saved to: {encoder_filepath}\")\n",
        "        return model_filepath, encoder_filepath\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving model or encoders to {save_path}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# --- Cell 4: Anomaly Detection Definition ---\n",
        "print(\"\\n--- Defining Anomaly Detection Function ---\")\n",
        "def detect_anomaly(model_filepath=\"/content/anomaly_model.pkl\",\n",
        "                   encoder_filepath=\"/content/encoders.pkl\",\n",
        "                   df_columns_trained=None, # Pass the column names from the training df\n",
        "                   original_data_path=None): # Path to original CSV for single-feature model fitting\n",
        "    \"\"\"Loads the saved model/encoders and performs anomaly detection based on user input.\"\"\"\n",
        "\n",
        "    if not os.path.exists(model_filepath) or not os.path.exists(encoder_filepath):\n",
        "        print(f\"Error: Model ('{model_filepath}') or encoder file ('{encoder_filepath}') not found. Please train and save first.\")\n",
        "        return None\n",
        "\n",
        "    if df_columns_trained is None:\n",
        "        print(\"Error: DataFrame column names from training are required.\")\n",
        "        return None\n",
        "\n",
        "    if original_data_path is None:\n",
        "        print(\"Error: Path to original data CSV is required for single-feature checks.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        with open(model_filepath, 'rb') as f:\n",
        "            model = pickle.load(f)\n",
        "        with open(encoder_filepath, 'rb') as f:\n",
        "            le_dict = pickle.load(f)\n",
        "        print(\"Model and encoders loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model or encoders: {e}\")\n",
        "        return None\n",
        "\n",
        "    categorical_cols = list(le_dict.keys())\n",
        "    all_possible_cols = df_columns_trained.tolist()\n",
        "    date_cols_created = ['invoice_day', 'invoice_month', 'invoice_year']\n",
        "\n",
        "    user_input_cols = [col for col in all_possible_cols if col not in date_cols_created]\n",
        "    if any(col in all_possible_cols for col in date_cols_created):\n",
        "        user_input_cols.append('invoice_date')\n",
        "    user_input_cols = sorted(list(set(user_input_cols)))\n",
        "\n",
        "    # --- Get User Input ---\n",
        "    while True:\n",
        "        prompt_text = f\"\\nEnter column to check (options: {', '.join(user_input_cols)}, all, quit): \"\n",
        "        anomaly_col_input = input(prompt_text).strip().lower()\n",
        "\n",
        "        if anomaly_col_input == 'quit':\n",
        "            return \"Exiting anomaly detection.\"\n",
        "        elif anomaly_col_input == 'all':\n",
        "            input_data = {}\n",
        "            print(\"\\nEnter values for the fields you want to check (press Enter to skip):\")\n",
        "            for col in user_input_cols:\n",
        "                 if col == 'invoice_date' or col in df_columns_trained:\n",
        "                     val_str = input(f\"Enter value for '{col}': \").strip()\n",
        "                     if val_str:\n",
        "                         input_data[col] = val_str\n",
        "            if not input_data:\n",
        "                print(\"No input provided for 'all'. Exiting.\")\n",
        "                return None\n",
        "            break\n",
        "        elif anomaly_col_input in user_input_cols:\n",
        "            val_str = input(f\"Enter the value for '{anomaly_col_input}': \").strip()\n",
        "            if not val_str:\n",
        "                 print(f\"No value entered for {anomaly_col_input}. Please try again.\")\n",
        "                 continue\n",
        "            input_data = {anomaly_col_input: val_str}\n",
        "            break\n",
        "        else:\n",
        "            print(f\"Invalid column name. Please choose from the options or type 'all'/'quit'.\")\n",
        "\n",
        "    # --- Prepare Input DataFrame (df_input) ---\n",
        "    df_input = pd.DataFrame(0.0, index=[0], columns=df_columns_trained)\n",
        "    processed_input_flag = False\n",
        "    original_input_values = {}\n",
        "\n",
        "    for col_input, val_str in input_data.items():\n",
        "        original_input_values[col_input] = val_str\n",
        "        processed_this_iter = False\n",
        "        try:\n",
        "            target_col = col_input # The actual column name in the dataframe\n",
        "            if col_input == 'invoice_date':\n",
        "                date_val = pd.to_datetime(val_str, format='%Y-%m-%d')\n",
        "                if 'invoice_day' in df_input.columns: df_input.loc[0,'invoice_day'] = float(date_val.day)\n",
        "                if 'invoice_month' in df_input.columns: df_input.loc[0,'invoice_month'] = float(date_val.month)\n",
        "                if 'invoice_year' in df_input.columns: df_input.loc[0,'invoice_year'] = float(date_val.year)\n",
        "                processed_this_iter = True\n",
        "            elif col_input in le_dict:\n",
        "                le = le_dict[col_input]\n",
        "                if val_str in le.classes_:\n",
        "                     df_input.loc[0, target_col] = float(le.transform([val_str])[0])\n",
        "                else:\n",
        "                     print(f\"Warning: Unseen label '{val_str}' for column '{target_col}'. Treating as 0. Anomaly likely.\")\n",
        "                     df_input.loc[0, target_col] = 0.0\n",
        "                processed_this_iter = True\n",
        "            elif col_input in df_columns_trained: # Numeric columns\n",
        "                 df_input.loc[0, target_col] = float(val_str)\n",
        "                 processed_this_iter = True\n",
        "\n",
        "            if processed_this_iter:\n",
        "                processed_input_flag = True\n",
        "\n",
        "        except ValueError:\n",
        "             print(f\"Invalid value format '{val_str}' for column '{col_input}'. Please enter a valid number or date (YYYY-MM-DD). Using 0.\")\n",
        "             if target_col in df_input.columns: df_input.loc[0, target_col] = 0.0\n",
        "        except Exception as e:\n",
        "             print(f\"Error processing input for {col_input} ('{val_str}'): {e}. Using 0.\")\n",
        "             if target_col in df_input.columns: df_input.loc[0, target_col] = 0.0\n",
        "\n",
        "\n",
        "    if not processed_input_flag :\n",
        "        print(\"Could not process any of the provided input values meaningfully.\")\n",
        "        return None\n",
        "\n",
        "    df_input.fillna(0.0, inplace=True)\n",
        "\n",
        "    # --- Make Prediction ---\n",
        "    anomaly_messages = []\n",
        "    anomaly_detected = False\n",
        "\n",
        "    try:\n",
        "        df_input_final = df_input[df_columns_trained] # Ensure columns match training\n",
        "\n",
        "        if anomaly_col_input == 'all':\n",
        "            print(\"Predicting based on the combination of provided inputs...\")\n",
        "            prediction = model.predict(df_input_final)\n",
        "            if prediction[0] == -1:\n",
        "                 anomaly_detected = True\n",
        "                 processed_vals_str = ', '.join([f\"{k}: {original_input_values.get(k, 'N/A')}\" for k in input_data])\n",
        "                 anomaly_messages.append(f\"Anomaly detected based on the combination of inputs: {processed_vals_str}\")\n",
        "\n",
        "        else: # Single feature check\n",
        "            print(f\"Predicting anomaly independently for '{anomaly_col_input}'...\")\n",
        "            temp_df, _, _ = preprocess_data(original_data_path) # Reload original preprocessed data\n",
        "            if temp_df is None:\n",
        "                print(f\"Error: Could not reload original data from '{original_data_path}' for single feature check.\")\n",
        "                return \"Error during single feature check.\"\n",
        "\n",
        "            cols_to_fit_predict = []\n",
        "            if anomaly_col_input == 'invoice_date':\n",
        "                cols_to_fit_predict = [col for col in date_cols_created if col in df_columns_trained]\n",
        "            elif anomaly_col_input in df_columns_trained:\n",
        "                cols_to_fit_predict = [anomaly_col_input]\n",
        "\n",
        "            if not cols_to_fit_predict:\n",
        "                 print(f\"Warning: Could not find required columns for '{anomaly_col_input}' in training data.\")\n",
        "            else:\n",
        "                # Ensure columns exist in both temp_df and df_input_final\n",
        "                cols_to_fit_predict = [col for col in cols_to_fit_predict if col in temp_df.columns and col in df_input_final.columns]\n",
        "                if not cols_to_fit_predict:\n",
        "                     print(f\"Error: Mismatch in columns for single feature check ('{anomaly_col_input}').\")\n",
        "                else:\n",
        "                    try:\n",
        "                        temp_model = IsolationForest(contamination=0.01, random_state=42) # Consistent parameters\n",
        "                        temp_model.fit(temp_df[cols_to_fit_predict]) # Fit only on the specific column(s)\n",
        "                        prediction = temp_model.predict(df_input_final[cols_to_fit_predict])\n",
        "                        if prediction[0] == -1:\n",
        "                            anomaly_detected = True\n",
        "                            anomaly_messages.append(f\"Anomaly detected in {anomaly_col_input}: {original_input_values.get(anomaly_col_input, 'N/A')}\")\n",
        "                    except Exception as fit_e:\n",
        "                        print(f\"Error fitting/predicting temporary model for {anomaly_col_input}: {fit_e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during prediction phase: {e}\")\n",
        "        return \"An error occurred during prediction.\"\n",
        "\n",
        "\n",
        "    if anomaly_detected:\n",
        "        return \"\\n\".join(anomaly_messages)\n",
        "    else:\n",
        "        # --- Corrected f-string for the 'no anomaly' message ---\n",
        "        if anomaly_col_input != 'all':\n",
        "            input_desc = f\"input ({anomaly_col_input}: {original_input_values.get(anomaly_col_input, 'N/A')})\"\n",
        "        else:\n",
        "            combined_inputs = ', '.join([f'{k}: {original_input_values.get(k, \"N/A\")}' for k in input_data])\n",
        "            input_desc = f\"combination of inputs: {combined_inputs}\"\n",
        "        # Now use the variable 'input_desc' safely\n",
        "        return f\"No anomaly detected for the provided {input_desc}.\"\n",
        "\n",
        "\n",
        "# === Jupyter Notebook Workflow (for Colab with file at /content/) ===\n",
        "\n",
        "# --- Cell 1: Preprocess Data ---\n",
        "print(\"--- Preprocessing Data ---\")\n",
        "df_train, le_dict, df_cols_trained = preprocess_data(invoices_file_path)\n",
        "\n",
        "if df_train is not None:\n",
        "    print(\"\\nPreprocessing complete.\")\n",
        "else:\n",
        "    print(\"\\nPreprocessing failed. Cannot proceed.\")\n",
        "    df_cols_trained = None # Ensure it's None if preprocessing fails\n",
        "\n",
        "# --- Cell 2: Train and Save Model (Run only once unless data changes) ---\n",
        "model_filepath, encoder_filepath = None, None\n",
        "if df_train is not None and le_dict is not None:\n",
        "    print(\"\\n--- Training and Saving Model ---\")\n",
        "    model_filepath, encoder_filepath = train_and_save_model(df_train, le_dict, save_path=model_save_path)\n",
        "    if model_filepath and encoder_filepath:\n",
        "        print(\"\\nModel training and saving complete.\")\n",
        "        print(\"\\nFiles in /content/:\")\n",
        "        # Use try-except in case /content doesn't exist locally\n",
        "        try:\n",
        "            print(os.listdir('/content/'))\n",
        "        except FileNotFoundError:\n",
        "            print(\"'/content/' directory not found (may not be in Colab).\")\n",
        "    else:\n",
        "        print(\"\\nModel training or saving failed.\")\n",
        "else:\n",
        "    print(\"\\nSkipping model training due to preprocessing errors.\")\n",
        "\n",
        "\n",
        "# --- Cell 3: Detect Anomalies (Run interactively as needed) ---\n",
        "if model_filepath and encoder_filepath and df_cols_trained is not None:\n",
        "    print(\"\\n--- Anomaly Detection ---\")\n",
        "    while True:\n",
        "        result = detect_anomaly(model_filepath=model_filepath,\n",
        "                                encoder_filepath=encoder_filepath,\n",
        "                                df_columns_trained=df_cols_trained,\n",
        "                                original_data_path=invoices_file_path)\n",
        "        if result:\n",
        "            print(\"\\n--- Result ---\")\n",
        "            print(result)\n",
        "            if result == \"Exiting anomaly detection.\":\n",
        "                break\n",
        "        else:\n",
        "            print(\"\\nAnomaly detection could not be performed or no anomalies found.\")\n",
        "\n",
        "        another_check = input(\"\\nCheck another anomaly? (yes/no): \").strip().lower()\n",
        "        if another_check != 'yes':\n",
        "            break\n",
        "\n",
        "    print(\"\\nAnomaly detection finished.\")\n",
        "else:\n",
        "    print(\"\\nModel not trained or saved correctly. Cannot perform anomaly detection.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mePxha9Eg5Cv",
        "outputId": "a353fbd6-bffa-497e-fab8-67322d36db9d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Setup ---\n",
            "Using invoice data file: /content/invoices.csv\n",
            "Model will be saved to/loaded from: /content/\n",
            "\n",
            "--- Defining Preprocessing Function ---\n",
            "\n",
            "--- Defining Model Training Function ---\n",
            "\n",
            "--- Defining Anomaly Detection Function ---\n",
            "--- Preprocessing Data ---\n",
            "Reading CSV from: /content/invoices.csv\n",
            "Initial DataFrame shape: (10000, 11)\n",
            "Encoding categorical columns...\n",
            "Processing invoice date...\n",
            "Columns selected for model training: ['address', 'amount', 'city', 'email', 'first_name', 'invoice_day', 'invoice_month', 'invoice_year', 'job', 'last_name', 'product_id', 'qty', 'stock_code']\n",
            "Final DataFrame info before returning:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Columns: 13 entries, address to stock_code\n",
            "dtypes: float64(1), int32(3), int64(9)\n",
            "memory usage: 898.6 KB\n",
            "\n",
            "Preprocessing complete.\n",
            "\n",
            "--- Training and Saving Model ---\n",
            "Fitting Isolation Forest model on 10000 samples and 13 features...\n",
            "Model fitting complete.\n",
            "Model successfully saved to: /content/anomaly_model.pkl\n",
            "Encoders successfully saved to: /content/encoders.pkl\n",
            "\n",
            "Model training and saving complete.\n",
            "\n",
            "Files in /content/:\n",
            "['.config', 'anomaly_model.pkl', 'encoders.pkl', 'invoices.csv', 'sample_data']\n",
            "\n",
            "--- Anomaly Detection ---\n",
            "Model and encoders loaded successfully.\n",
            "\n",
            "Enter column to check (options: address, amount, city, email, first_name, invoice_date, job, last_name, product_id, qty, stock_code, all, quit): product_id\n",
            "Enter the value for 'product_id': 169\n",
            "Predicting anomaly independently for 'product_id'...\n",
            "Reading CSV from: /content/invoices.csv\n",
            "Initial DataFrame shape: (10000, 11)\n",
            "Encoding categorical columns...\n",
            "Processing invoice date...\n",
            "Columns selected for model training: ['address', 'amount', 'city', 'email', 'first_name', 'invoice_day', 'invoice_month', 'invoice_year', 'job', 'last_name', 'product_id', 'qty', 'stock_code']\n",
            "Final DataFrame info before returning:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Columns: 13 entries, address to stock_code\n",
            "dtypes: float64(1), int32(3), int64(9)\n",
            "memory usage: 898.6 KB\n",
            "\n",
            "--- Result ---\n",
            "No anomaly detected for the provided input (product_id: 169).\n",
            "\n",
            "Check another anomaly? (yes/no): yes\n",
            "Model and encoders loaded successfully.\n",
            "\n",
            "Enter column to check (options: address, amount, city, email, first_name, invoice_date, job, last_name, product_id, qty, stock_code, all, quit): product_id\n",
            "Enter the value for 'product_id': 420\n",
            "Predicting anomaly independently for 'product_id'...\n",
            "Reading CSV from: /content/invoices.csv\n",
            "Initial DataFrame shape: (10000, 11)\n",
            "Encoding categorical columns...\n",
            "Processing invoice date...\n",
            "Columns selected for model training: ['address', 'amount', 'city', 'email', 'first_name', 'invoice_day', 'invoice_month', 'invoice_year', 'job', 'last_name', 'product_id', 'qty', 'stock_code']\n",
            "Final DataFrame info before returning:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Columns: 13 entries, address to stock_code\n",
            "dtypes: float64(1), int32(3), int64(9)\n",
            "memory usage: 898.6 KB\n",
            "\n",
            "--- Result ---\n",
            "Anomaly detected in product_id: 420\n",
            "\n",
            "Check another anomaly? (yes/no): yes\n",
            "Model and encoders loaded successfully.\n",
            "\n",
            "Enter column to check (options: address, amount, city, email, first_name, invoice_date, job, last_name, product_id, qty, stock_code, all, quit): invoice_date\n",
            "Enter the value for 'invoice_date': 11-12-2025\n",
            "Invalid value format '11-12-2025' for column 'invoice_date'. Please enter a valid number or date (YYYY-MM-DD). Using 0.\n",
            "Could not process any of the provided input values meaningfully.\n",
            "\n",
            "Anomaly detection could not be performed or no anomalies found.\n",
            "\n",
            "Check another anomaly? (yes/no): yes\n",
            "Model and encoders loaded successfully.\n",
            "\n",
            "Enter column to check (options: address, amount, city, email, first_name, invoice_date, job, last_name, product_id, qty, stock_code, all, quit): invoice_date\n",
            "Enter the value for 'invoice_date': 11-12-2003\n",
            "Invalid value format '11-12-2003' for column 'invoice_date'. Please enter a valid number or date (YYYY-MM-DD). Using 0.\n",
            "Could not process any of the provided input values meaningfully.\n",
            "\n",
            "Anomaly detection could not be performed or no anomalies found.\n",
            "\n",
            "Check another anomaly? (yes/no): no\n",
            "\n",
            "Anomaly detection finished.\n"
          ]
        }
      ]
    }
  ]
}