
UPDATED VERSION IS ON BRANCH V2
```markdown
# ğŸ§  Invoice Anomaly Detection App

A simple **AI-powered anomaly detection** web application built with **Streamlit** and **Scikit-learn (Isolation Forest)**.  
The app detects unusual invoice entries using your trained model and provides real-time predictions via an interactive web interface.

---

## ğŸš€ Features

- ğŸ” Detects anomalies in invoice data using **Isolation Forest**
- ğŸ§¹ Automatic data preprocessing and training
- ğŸ’¾ Saves trained model, encoders, and column metadata
- ğŸŒ Clean and interactive **Streamlit UI**
- âš¡ Automatically trains only once if model files are missing

---

## ğŸ§© Project Structure

```

invoice-anomaly-app/
â”‚
â”œâ”€â”€ app.py                     # Main Streamlit application
â”œâ”€â”€ model.pkl                  # Trained Isolation Forest model (auto-generated)
â”œâ”€â”€ encoders.pkl               # Encoded categorical data mappings (auto-generated)
â”œâ”€â”€ columns.pkl                # List of columns used for training (auto-generated)
â”œâ”€â”€ data.csv                   # Dataset file
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md                  # Project documentation

````

---

## ğŸ§° Requirements

Ensure you have **Python 3.8+** installed.

### Install dependencies

```bash
pip install -r requirements.txt
````

Or manually install **Streamlit** (if not already included):

```bash
pip install streamlit
```

---

## âš™ï¸ How It Works

1. The app checks if model files (`model.pkl`, `encoders.pkl`, `columns.pkl`) exist.

   * If not, it **preprocesses** your dataset and **trains** a new model.
2. The trained model, encoders, and column list are saved locally.
3. When the app runs, it loads these files and displays a form in the UI.
4. You enter invoice details â†’ The app encodes the input â†’ Runs anomaly detection.
5. It displays whether your input is **Normal** or **Anomalous**.

---

## â–¶ï¸ Run the App

You can start the app in either of these two ways:

### Option 1 â€” Using Python

```bash
python app.py
```

### Option 2 â€” Using Streamlit

```bash
streamlit run app.py
```

After running, Streamlit will launch the web app at:
ğŸ‘‰ `http://localhost:8501`

---

## ğŸ§  Example Workflow

1. Launch the app with `streamlit run app.py`.
2. Fill in invoice details in the input form.
3. Click **Submit**.
4. The app shows:

   * âœ… **Normal** â†’ Data is consistent with learned patterns.
   * âš ï¸ **Anomalous** â†’ Detected deviation or unusual pattern.

---

## ğŸ“¦ Model Files

These files are generated automatically during training:

| File           | Description                               |
| -------------- | ----------------------------------------- |
| `model.pkl`    | Trained Isolation Forest model            |
| `encoders.pkl` | Label encoders for categorical columns    |
| `columns.pkl`  | List of dataset columns used for training |

---

## ğŸ§¾ Example `requirements.txt`

If you donâ€™t have a requirements file yet, you can create one with the following content:

```
pandas
numpy
scikit-learn
streamlit
joblib
```

Install them using:

```bash
pip install -r requirements.txt
```

---

## ğŸ’¡ Example Code Snippet (app.py)

Below is a **minimal structure** for your `app.py` file if you want to verify your setup:

```python
import streamlit as st
import pandas as pd
import joblib
import os
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import LabelEncoder

# ---- Preprocessing Function ----
def preprocess_data(df):
    for col in df.select_dtypes(include=['object']).columns:
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col])
    return df

# ---- Train and Save Model ----
def train_and_save_model(data_path='data.csv'):
    df = pd.read_csv(data_path)
    df = preprocess_data(df)

    model = IsolationForest(contamination=0.05, random_state=42)
    model.fit(df)

    joblib.dump(model, 'model.pkl')
    joblib.dump(list(df.columns), 'columns.pkl')
    return model

# ---- Load or Train ----
def load_or_train_model():
    if os.path.exists('model.pkl') and os.path.exists('columns.pkl'):
        model = joblib.load('model.pkl')
        columns = joblib.load('columns.pkl')
    else:
        model = train_and_save_model()
        columns = joblib.load('columns.pkl')
    return model, columns

# ---- Streamlit App ----
st.title("ğŸ§  Invoice Anomaly Detection")

model, columns = load_or_train_model()

# Input Form
with st.form("input_form"):
    st.subheader("Enter Invoice Details")
    inputs = {col: st.text_input(col) for col in columns}
    submitted = st.form_submit_button("Submit")

    if submitted:
        input_df = pd.DataFrame([inputs])
        input_df = preprocess_data(input_df)
        prediction = model.predict(input_df)[0]
        result = "âœ… Normal" if prediction == 1 else "âš ï¸ Anomalous"
        st.success(f"Result: {result}")
```

---

## ğŸ’¡ Future Enhancements

* ğŸ“Š Add anomaly score visualizations
* ğŸ“ Support batch uploads for multi-record detection
* ğŸ’¾ Integrate database logging for results
* ğŸŒ Deploy using **Streamlit Cloud** or **AWS EC2**

---

